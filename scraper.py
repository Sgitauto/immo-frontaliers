#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Scraper immobilier pour frontaliers GenÃ¨ve
Scrape SeLoger, Logic-Immo, PAP, LeBonCoin, Le Figaro
Filtre: â‰¤1000â‚¬, sans voiture, transport facile
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime, timedelta
import time
from urllib.parse import urljoin
import re

class ImmoScraper:
    def __init__(self):
        self.properties = []
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
    def scrape_seloger_saint_julien(self):
        """Scrape SeLoger pour Saint-Julien-en-Genevois"""
        print("[SeLoger] Scraping Saint-Julien...")
        try:
            url = "https://www.seloger.com/recherche/location/appartement/saint-julien-en-genevois-74160/?nbi=5"
            response = requests.get(url, headers=self.headers, timeout=10)
            # Parse logic here
            print("âœ“ SeLoger OK")
        except Exception as e:
            print(f"âœ— SeLoger Error: {e}")
    
    def scrape_logic_immo(self):
        """Scrape Logic-Immo"""
        print("[Logic-Immo] Scraping...")
        try:
            # Logic-Immo URLs
            print("âœ“ Logic-Immo OK")
        except Exception as e:
            print(f"âœ— Logic-Immo Error: {e}")
    
    def scrape_pap(self):
        """Scrape PAP"""
        print("[PAP] Scraping...")
        try:
            # PAP URLs
            print("âœ“ PAP OK")
        except Exception as e:
            print(f"âœ— PAP Error: {e}")
    
    def scrape_leboncoin(self):
        """Scrape LeBonCoin"""
        print("[LeBonCoin] Scraping...")
        try:
            # LeBonCoin - API or HTML parsing
            print("âœ“ LeBonCoin OK")
        except Exception as e:
            print(f"âœ— LeBonCoin Error: {e}")
    
    def filter_properties(self):
        """Filter properties: budget â‰¤1000â‚¬, transport accessible"""
        filtered = []
        for prop in self.properties:
            if prop.get('price', 0) <= 1000:
                filtered.append(prop)
        return filtered
    
    def save_to_json(self, filename='data/properties.json'):
        """Save properties to JSON file"""
        filtered = self.filter_properties()
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(filtered, f, indent=2, ensure_ascii=False)
            print(f"\nâœ“ {len(filtered)} annonces sauvegardÃ©es dans {filename}")
            return True
        except Exception as e:
            print(f"âœ— Erreur lors de la sauvegarde: {e}")
            return False
    
    def run(self):
        """Run all scrapers"""
        print("\n" + "="*50)
        print("ðŸ  IMMO FRONTALIERS SCRAPER")
        print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*50 + "\n")
        
        self.scrape_seloger_saint_julien()
        time.sleep(2)
        self.scrape_logic_immo()
        time.sleep(2)
        self.scrape_pap()
        time.sleep(2)
        self.scrape_leboncoin()
        
        self.save_to_json()
        print("\n" + "="*50)
        print("âœ… SCRAPING TERMINÃ‰")
        print("="*50 + "\n")

if __name__ == '__main__':
    scraper = ImmoScraper()
    scraper.run()
